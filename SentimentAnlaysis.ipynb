{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "721274a4",
      "metadata": {
        "id": "721274a4"
      },
      "source": [
        "Import Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f1497538",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1497538",
        "outputId": "f969b190-2242-45a7-bd68-44754ad01098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ਕੁੱਝ ਵਿਦਵਾਨਾਂ ਲਈ ਤਾਂ ‘ਕਹਾਣੀ ਸਹਿਜ ਸਾਧਾਰਣ ਸੱਚ ਨੂੰ ਸਰਲ ਸਪਾਟ ਰੂਪ ਵਿਚ ਕਹਿੰਦੀ ਹੈ’ ਅਤੇ ‘ਏਸ ਕਲਾ ਨੂੰ... ਕਿਸੇ ਗੁੰਝਲਦਾਰ ਸਾਹਿਤ ਸ਼ਾਸਤਰ ਦੀ ਮੁਹਤਾਜ਼ੀ ਨਹੀਂ ।’ ਪਰ ਸਹਿਜ ਸਾਧਾਰਣ ਸੱਚ ਨੂੰ ਨਾ ਕਹਾਣੀ ਸਰਲ ਸਪਾਟ ਰੂਪ ਵਿਚ ਪੇਸ਼ ਕਰਦੀ ਹੈ ਅਤੇ ਨਾ ਹੀ ਇਸ ਦਾ ਸਾਹਿਤ ਸ਼ਾਸਤਰ ਏਨਾ ਸਰਲ ਰਹੇਗਾ । ਜਿਸ ਤਰ੍ਹਾਂ ਕਵਿਤਾ ਕੇਵਲ ਛੰਦ ਪ੍ਰਬੰਧ ਨਹੀਂ ਹੁੰਦੀ, ਇਸੇ ਤਰ੍ਹਾਂ ਕਹਾਣੀ ਕੇਵਲ ਕਹਾਣੀ (ਕਥਾ) ਨਹੀਂ ਹੁੰਦੀ । ਕਹਾਣੀ ਦੀ ਗੱਲ ਜਦੋਂ ਅਸੀਂ ਇਕ ਰੂਪਾਕਾਰ ਦੇ ਦ੍ਰਿਸ਼ਟੀਕੋਣ ਤੋਂ ਕਰਦੇ ਹਾਂ ਤਾਂ ਇਹ ਵੀ ਕਥਾ ਦੇ ਪਰੰਪਰਾਈ ਰੂਪ ਨੂੰ ਤਜ ਕੇ ਨਵੀਆਂ ਸੰਭਾਵਨਾਵਾਂ ਨਾਲ ਜਾ ਜੁੜਦੀ ਹੈ ।\n",
            "ਬਿਰਤਾਂਤ ਦੀ ਬਿਰਤੀ ਵਧੇਰੇ ਕਰਕੇ \n"
          ]
        }
      ],
      "source": [
        "text = open('ExtractedText.txt', encoding='utf-8').read()\n",
        "print(text[:500]) #Print the first 500 letters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a371336",
      "metadata": {
        "id": "4a371336"
      },
      "source": [
        "Split corpus into sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "98900d9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98900d9f",
        "outputId": "98046a26-59dc-4eae-fa45-9d9000315cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences: 5786\n",
            "['ਕੁੱਝ ਵਿਦਵਾਨਾਂ ਲਈ ਤਾਂ ‘ਕਹਾਣੀ ਸਹਿਜ ਸਾਧਾਰਣ ਸੱਚ ਨੂੰ ਸਰਲ ਸਪਾਟ ਰੂਪ ਵਿਚ ਕਹਿੰਦੀ ਹੈ’ ਅਤੇ ‘ਏਸ ਕਲਾ ਨੂੰ... ਕਿਸੇ ਗੁੰਝਲਦਾਰ ਸਾਹਿਤ ਸ਼ਾਸਤਰ ਦੀ ਮੁਹਤਾਜ਼ੀ ਨਹੀਂ', '’ ਪਰ ਸਹਿਜ ਸਾਧਾਰਣ ਸੱਚ ਨੂੰ ਨਾ ਕਹਾਣੀ ਸਰਲ ਸਪਾਟ ਰੂਪ ਵਿਚ ਪੇਸ਼ ਕਰਦੀ ਹੈ ਅਤੇ ਨਾ ਹੀ ਇਸ ਦਾ ਸਾਹਿਤ ਸ਼ਾਸਤਰ ਏਨਾ ਸਰਲ ਰਹੇਗਾ', 'ਜਿਸ ਤਰ੍ਹਾਂ ਕਵਿਤਾ ਕੇਵਲ ਛੰਦ ਪ੍ਰਬੰਧ ਨਹੀਂ ਹੁੰਦੀ, ਇਸੇ ਤਰ੍ਹਾਂ ਕਹਾਣੀ ਕੇਵਲ ਕਹਾਣੀ (ਕਥਾ) ਨਹੀਂ ਹੁੰਦੀ']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "sentenceEnd = ['|', '।']\n",
        "pattern = f\"[{''.join(re.escape(ch) for ch in sentenceEnd)}]\"\n",
        "corpus = re.split(pattern, text)\n",
        "corpus = [s.strip() for s in corpus if s.strip()]\n",
        "print(\"Total sentences:\", len(corpus))\n",
        "print(corpus[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b4e7d8",
      "metadata": {
        "id": "69b4e7d8"
      },
      "source": [
        "Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bd69a5c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd69a5c9",
        "outputId": "2d2658d5-feb8-4d28-b834-e941c4b6d683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ਕੁੱਝ ਵਿਦਵਾਨਾਂ ਲਈ ਤਾਂ ਕਹਾਣੀ ਸਹਿਜ ਸਾਧਾਰਣ ਸੱਚ ਨੂੰ ਸਰਲ ਸਪਾਟ ਰੂਪ ਵਿਚ ਕਹਿੰਦੀ ਹੈ ਅਤੇ ਏਸ ਕਲਾ ਨੂੰ ਕਿਸੇ ਗੁੰਝਲਦਾਰ ਸਾਹਿਤ ਸ਼ਾਸਤਰ ਦੀ ਮੁਹਤਾਜ਼ੀ ਨਹੀਂ', ' ਪਰ ਸਹਿਜ ਸਾਧਾਰਣ ਸੱਚ ਨੂੰ ਨਾ ਕਹਾਣੀ ਸਰਲ ਸਪਾਟ ਰੂਪ ਵਿਚ ਪੇਸ਼ ਕਰਦੀ ਹੈ ਅਤੇ ਨਾ ਹੀ ਇਸ ਦਾ ਸਾਹਿਤ ਸ਼ਾਸਤਰ ਏਨਾ ਸਰਲ ਰਹੇਗਾ', 'ਜਿਸ ਤਰ੍ਹਾਂ ਕਵਿਤਾ ਕੇਵਲ ਛੰਦ ਪ੍ਰਬੰਧ ਨਹੀਂ ਹੁੰਦੀ ਇਸੇ ਤਰ੍ਹਾਂ ਕਹਾਣੀ ਕੇਵਲ ਕਹਾਣੀ ਕਥਾ ਨਹੀਂ ਹੁੰਦੀ']\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "punctuations = string.punctuation + '।' + '\\n' + '‘’'\n",
        "def cleanSentence(sentence):\n",
        "    return sentence.translate(str.maketrans('', '', punctuations))\n",
        "\n",
        "cleanedSentences = [cleanSentence(s) for s in corpus]\n",
        "print(cleanedSentences[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b319e13a",
      "metadata": {
        "id": "b319e13a"
      },
      "source": [
        "Import Stopwords, tokenise sentences and remove stopwords from corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "19b16bba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19b16bba",
        "outputId": "c593b6d6-e35d-48b8-e8f0-4a82f19aeee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['ਕੁੱਝ', 'ਵਿਦਵਾਨਾਂ', 'ਕਹਾਣੀ', 'ਸਹਿਜ', 'ਸਾਧਾਰਣ', 'ਸੱਚ', 'ਸਰਲ', 'ਸਪਾਟ', 'ਰੂਪ', 'ਵਿਚ', 'ਕਹਿੰਦੀ', 'ਕਲਾ', 'ਕਿਸੇ', 'ਗੁੰਝਲਦਾਰ', 'ਸਾਹਿਤ', 'ਸ਼ਾਸਤਰ', 'ਦੀ', 'ਮੁਹਤਾਜ਼ੀ', 'ਨਹੀਂ'], ['ਸਹਿਜ', 'ਸਾਧਾਰਣ', 'ਸੱਚ', 'ਨਾ', 'ਕਹਾਣੀ', 'ਸਰਲ', 'ਸਪਾਟ', 'ਰੂਪ', 'ਵਿਚ', 'ਪੇਸ਼', 'ਕਰਦੀ', 'ਨਾ', 'ਇਸ', 'ਸਾਹਿਤ', 'ਸ਼ਾਸਤਰ', 'ਏਨਾ', 'ਸਰਲ', 'ਰਹੇਗਾ'], ['ਜਿਸ', 'ਤਰ੍ਹਾਂ', 'ਕਵਿਤਾ', 'ਕੇਵਲ', 'ਛੰਦ', 'ਪ੍ਰਬੰਧ', 'ਨਹੀਂ', 'ਹੁੰਦੀ', 'ਇਸੇ', 'ਤਰ੍ਹਾਂ', 'ਕਹਾਣੀ', 'ਕੇਵਲ', 'ਕਹਾਣੀ', 'ਕਥਾ', 'ਨਹੀਂ', 'ਹੁੰਦੀ']]\n"
          ]
        }
      ],
      "source": [
        "with open('Stopwords.txt', 'r', encoding='utf-8') as f:\n",
        "    stopWords = [word.strip('\"') for word in f.read().split(',')]\n",
        "\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "\n",
        "sentencesWithoutStopwords = []\n",
        "for sentence in cleanedSentences:\n",
        "    tokens = indic_tokenize.trivial_tokenize(sentence)\n",
        "    filteredTokens = [token for token in tokens if token not in stopWords]\n",
        "    sentencesWithoutStopwords.append(filteredTokens)\n",
        "\n",
        "print(sentencesWithoutStopwords[:3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "447fb99c",
      "metadata": {
        "id": "447fb99c"
      },
      "source": [
        "Import Lexicon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "65cd8f52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65cd8f52",
        "outputId": "ca522720-350a-43fd-c6a4-23c6704e1fa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  English Word  anger  anticipation  disgust  fear  joy  negative  positive  \\\n",
            "0       abacus      0             0        0     0    0         0         0   \n",
            "1      abandon      0             0        0     1    0         1         0   \n",
            "2    abandoned      1             0        0     1    0         1         0   \n",
            "3  abandonment      1             0        0     1    0         1         0   \n",
            "4         abba      0             0        0     0    0         0         1   \n",
            "\n",
            "   sadness  surprise  trust Punjabi Word  \n",
            "0        0         0      1       abacus  \n",
            "1        1         0      0     ਛੱਡ ਦੇਣਾ  \n",
            "2        1         0      0    ਛੱਡ ਦਿੱਤਾ  \n",
            "3        1         1      0         ਤਿਆਗ  \n",
            "4        0         0      0         ਅੱਬਾ  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "emotions = ['anger', 'anticipation', 'disgust', 'fear', 'joy',\n",
        "            'negative', 'positive', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "lexiconDf = pd.read_csv('Punjabi-NRC-EmoLex.txt', sep='\\t', encoding='utf-8')\n",
        "\n",
        "#Filter out rows that are 0 for all emotions\n",
        "lexiconFiltered = lexiconDf[lexiconDf[emotions].sum(axis=1) > 0]\n",
        "lexiconFiltered = lexiconFiltered.reset_index(drop=True)\n",
        "\n",
        "print(lexiconFiltered.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "340097a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "340097a7",
        "outputId": "b3d232e9-270b-4ff9-f0c0-adc0316e12ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fear', 'negative', 'sadness']\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "emotionLexicon = defaultdict(list)\n",
        "for _, row in lexiconDf.iterrows():\n",
        "    punjabi_word = str(row['Punjabi Word']).strip()\n",
        "    for emotion in emotions:\n",
        "        if row[emotion] == 1:\n",
        "            emotionLexicon[punjabi_word].append(emotion)\n",
        "\n",
        "#Test to see if everything is loaded correctly\n",
        "print(emotionLexicon['ਛੱਡ ਦੇਣਾ'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa5a6e7",
      "metadata": {
        "id": "8fa5a6e7"
      },
      "source": [
        "Generate features and generate labels through the lexicon per sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "385463ad",
      "metadata": {
        "id": "385463ad"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "def autoLabel(tokens, lexicon):\n",
        "    emoCounts = Counter()\n",
        "    for token in tokens:\n",
        "        for em in lexicon.get(token, []):\n",
        "            emoCounts[em] = emoCounts[em] + 1\n",
        "    if not emoCounts:\n",
        "        return 'neutral'\n",
        "    return emoCounts.most_common(1)[0][0]\n",
        "\n",
        "def getEmotionVector(tokens):\n",
        "    counts = Counter()\n",
        "    for token in tokens:\n",
        "        for em in emotionLexicon.get(token, []):\n",
        "            counts[em] += 1\n",
        "    return np.array([counts.get(em, 0) for em in emotions])\n",
        "\n",
        "# Features and labels\n",
        "xFeatures = np.array([getEmotionVector(tokens) for tokens in sentencesWithoutStopwords])\n",
        "yLabels = [autoLabel(tokens, emotionLexicon) for tokens in sentencesWithoutStopwords]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5941949c",
      "metadata": {
        "id": "5941949c"
      },
      "source": [
        "Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "322192a9",
      "metadata": {
        "id": "322192a9"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "yEncoded = le.fit_transform(yLabels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "068dbd11",
      "metadata": {
        "id": "068dbd11"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "404164bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "404164bd",
        "outputId": "57d8019c-752c-4f6c-97f9-80a953a6a23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xFeatures shape: (5786, 10)\n",
            "yEncoded shape: (5786,)\n"
          ]
        }
      ],
      "source": [
        "print(\"xFeatures shape:\", xFeatures.shape)\n",
        "print(\"yEncoded shape:\", yEncoded.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c119f5",
      "metadata": {
        "id": "15c119f5"
      },
      "source": [
        "Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4c7e09ed",
      "metadata": {
        "id": "4c7e09ed"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xTrain, xPred, yTrain, yPred = train_test_split(xFeatures, yEncoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac31776c",
      "metadata": {
        "id": "ac31776c"
      },
      "source": [
        "Build and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "03499984",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03499984",
        "outputId": "1c372ec9-ecd1-43d4-d8a3-be04bdd4826b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2933 - loss: 2.1703\n",
            "Epoch 2/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 1.3901\n",
            "Epoch 3/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.9600\n",
            "Epoch 4/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.7103\n",
            "Epoch 5/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.5638\n",
            "Epoch 6/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.5043\n",
            "Epoch 7/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.4592\n",
            "Epoch 8/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8430 - loss: 0.4103\n",
            "Epoch 9/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3761\n",
            "Epoch 10/10\n",
            "\u001b[1m290/290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.3499\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x784b524583d0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(len(emotions),)),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(len(set(yEncoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(xTrain, yTrain, epochs=10, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab459abc",
      "metadata": {
        "id": "ab459abc"
      },
      "source": [
        "Test prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8f119345",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f119345",
        "outputId": "57dd99ea-16df-473a-8674-aec2099b82ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Predicted: ['positive']\n"
          ]
        }
      ],
      "source": [
        "sample = \"ਮੈਂ ਬਹੁਤ ਖੁਸ਼ ਹਾਂ\"\n",
        "tokens = indic_tokenize.trivial_tokenize(sample)\n",
        "features = getEmotionVector(tokens).reshape(1, -1)\n",
        "pred_class = model.predict(features).argmax(axis=1)\n",
        "print(\"Predicted:\", le.inverse_transform(pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cosneIFZuBaz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cosneIFZuBaz",
        "outputId": "3b3ef739-83fb-4239-d355-111409a52d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "[[ 33   0   0   0   0   0   0   0   0   0]\n",
            " [  0  82   0   0   0   0   0   0   0   0]\n",
            " [  0   0  17   0   0   0   0   0   0   0]\n",
            " [  0   0   0  30   0   0   0   0   0   0]\n",
            " [  0   0   0   0  22   0   0   0   0   0]\n",
            " [  0   0   0   0   0 227   0   0   0   0]\n",
            " [  0   0   0   0   0   0 344   0   0   0]\n",
            " [  0   0   0   0   0   0   0 360   0   0]\n",
            " [  0   0   0   0   0   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0  42]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "yPred = model.predict(xPred).argmax(axis=1)\n",
        "cm = confusion_matrix(yPred, yPred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LmvVBiJovKwX",
      "metadata": {
        "id": "LmvVBiJovKwX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
